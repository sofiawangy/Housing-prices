{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "from matplotlib import cm\n",
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "train = pd.read_csv('train.csv', index_col = 0)\n",
    "test = pd.read_csv('test.csv', index_col = 0)\n",
    "\n",
    "#get info\n",
    "\n",
    "def get_details(data):\n",
    "    skew= data.skew()\n",
    "    corr = data.corr()['SalePrice']\n",
    "\n",
    "    nulls = data.apply(lambda x: x.isnull().sum())\n",
    "    nulls_perc = data.apply(lambda x: x.isnull().sum()/data.shape[0]*100)\n",
    "    unique = data.apply(lambda x: [x.unique()])\n",
    "\n",
    "    details = pd.concat([skew, corr, nulls, nulls_perc, unique], axis=1, sort=False)\n",
    "    details.columns = ['skew', 'corr', 'nulls', 'nulls_perc', 'unique']\n",
    "    \n",
    "    return details\n",
    "    \n",
    "def get_features(model, x, y):\n",
    "    \n",
    "    model.fit(x, y)\n",
    "    feature_importance = {}\n",
    "\n",
    "    for i, col in enumerate(x.columns):\n",
    "        feature_importance[col] = model.feature_importances_[i]\n",
    "\n",
    "    return {k: v for k, v in sorted(feature_importance.items(), key=lambda item: item[1],reverse=True)}\n",
    "\n",
    "def lift_table(actual, pred, weight=None, n=10, xlab='Predicted Decile', MyTitle='Model Performance Lift Chart'):\n",
    "\n",
    "    if weight is None:\n",
    "        weight=np.ones((1,len(actual)))\n",
    "\n",
    "    pdf= pd.DataFrame(sp.vstack([actual,pred,weight]).T,columns=['Actual','Predicted','Weight'],)\n",
    "    pdf= pdf.sort_values(by='Predicted')\n",
    "\n",
    "    pdf['CummulativeWeight'] = np.cumsum(pdf['Weight'].astype(float))\n",
    "    pdf['CummulativeWeightedActual'] = np.cumsum(pdf['Actual']*pdf['Weight'])\n",
    "\n",
    "    TotalWeight = sum(pdf['Weight'])\n",
    "\n",
    "    pdf['PredictedDecile'] = np.round(pdf['CummulativeWeight']*n /TotalWeight + 0.5,decimals=0)\n",
    "    pdf['PredictedDecile'][pdf['PredictedDecile'] < 1.0] = 1.0\n",
    "    pdf['PredictedDecile'][pdf['PredictedDecile'] > n] = n\n",
    "    pdf['WeightedPrediction'] = pdf['Predicted']*pdf['Weight']\n",
    "    pdf['WeightedActual'] = pdf['Actual']*pdf['Weight']\n",
    "\n",
    "    lift_df = pdf.groupby('PredictedDecile').agg({'WeightedPrediction': np.sum,'Weight':np.sum,'WeightedActual':np.sum,'PredictedDecile':np.size})\n",
    "\n",
    "    lift_df['AveragePrediction'] = lift_df['WeightedPrediction']/lift_df['Weight']\n",
    "    lift_df['AverageActual'] = lift_df['WeightedActual']/lift_df['Weight']\n",
    "    lift_df['AverageError'] = lift_df['AverageActual']/lift_df['AveragePrediction']\n",
    "\n",
    "    return lift_df\n",
    "\n",
    "def plot_lift(lift_df):\n",
    "\n",
    "    n=lift_df.shape[0]\n",
    "    d = pd.DataFrame(lift_df.index)\n",
    "    p = list(lift_df['AveragePrediction'])#p = list(lift_df['AveragePredictionBalanced'])\n",
    "    a = list(lift_df['AverageActual'])\n",
    "\n",
    "    mean_actual=np.mean(a)\n",
    "    p.reverse()\n",
    "    a.reverse()\n",
    "\n",
    "    lift=a[0]/mean_actual\n",
    "\n",
    "    plt.plot(d,p,label='Predicted',color='blue',marker='o')\n",
    "    plt.plot(d,a,label='Actual',color='red',marker='d')\n",
    "    plt.plot(range(1,n+1),[mean_actual]*n,'--',label='Mean',color='k',marker=None)\n",
    "    plt.legend(['Predicted','Actual','Mean'])\n",
    "    plt.xlabel('decile')\n",
    "    plt.ylabel('Actual vs. Predicted')\n",
    "    plt.text(n-2,1.2*mean_actual, 'lift = {0:.2f} '.format(lift))\n",
    "    plt.show()\n",
    "\n",
    "cat = train.select_dtypes(include=['O']).columns\n",
    "cont = train.select_dtypes(exclude=['O']).columns\n",
    "\n",
    "details = get_details(train[cont]).sort_values('corr', ascending = False).iloc[1:].head(12)\n",
    "\n",
    "train = train.loc[train.GrLivArea <= 4500]\n",
    "train = train.loc[train.TotalBsmtSF < 6000]\n",
    "train = train.loc[train['1stFlrSF'] < 4000]\n",
    "\n",
    "data = pd.concat([train, test], sort=False).reset_index(drop=True)\n",
    "\n",
    "#impute NaN\n",
    "\n",
    "data['PoolQC'].loc[data.PoolQC.isnull() & data.PoolArea == 0] = 'NA'\n",
    "data['MiscFeature'].loc[data.MiscFeature.isnull() & (data.MiscVal == 0)] = 'NA'\n",
    "data['Alley'].loc[data.Alley.isnull()] = 'NA'\n",
    "data['Fence'].loc[data.Fence.isnull()] = 'NA'\n",
    "data['FireplaceQu'].loc[data.FireplaceQu.isnull()] = 'NA'\n",
    "data['LotFrontage'].loc[data.LotFrontage.isnull()] = 0\n",
    "\n",
    "fill = pd.Series([data[c].value_counts().index[0] for c in data[cat]],\n",
    "            index=data[cat].columns)\n",
    "\n",
    "data[cat] = data[cat].fillna(fill)\n",
    "\n",
    "details = get_details(data)\n",
    "\n",
    "fill = ['MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2','BsmtUnfSF', 'TotalBsmtSF', 'GarageArea']\n",
    "\n",
    "for i in fill:\n",
    "    data.loc[data[i].isnull(), i] = data.groupby(['OverallQual', 'Neighborhood'])[i].transform(lambda x: x.fillna(x.mean()))\n",
    "    \n",
    "fill = ['BsmtFullBath', 'BsmtHalfBath', 'GarageYrBlt', 'GarageCars', 'GarageYrBlt']\n",
    "\n",
    "for i in fill:\n",
    "    data.loc[data[i].isnull(), i] = data.groupby(['OverallQual', 'Neighborhood'])[i].transform(lambda x: x.fillna(x.median()))\n",
    "    \n",
    "data.loc[data['GarageYrBlt'].isnull(), 'GarageYrBlt'] = data.GarageYrBlt.median()\n",
    "    \n",
    "data = data.drop(['Utilities'], axis = 1)\n",
    "    \n",
    "cat = cat.to_list()\n",
    "cat.remove('Utilities')\n",
    "\n",
    "dummy = pd.get_dummies(data[cat])\n",
    "\n",
    "data = pd.concat([data, dummy], axis =1)\n",
    "data = data.drop(cat, axis = 1)\n",
    "\n",
    "data.loc[data['SalePrice'].isnull(), 'SalePrice'] = 0\n",
    "\n",
    "details = get_details(data[cont]).sort_values('skew', ascending = False)\n",
    "\n",
    "no_log = data\n",
    "\n",
    "cols = details.loc[abs(details['skew']) > 0.7].index.to_list()\n",
    "cols.remove('SalePrice')\n",
    "\n",
    "# Boxcox\n",
    "data.loc[:, 'SalePrice'], l_opt = boxcox(data.loc[:, 'SalePrice'] + 1) \n",
    "\n",
    "data = data.drop('MiscVal', axis = 1)\n",
    "data_copy = data\n",
    "\n",
    "#go back to train and test\n",
    "train  = data.loc[data.SalePrice > 0,]\n",
    "test = data.loc[data.SalePrice == 0,]\n",
    "\n",
    "x = train.drop('SalePrice', axis = 1)\n",
    "y = train['SalePrice']\n",
    "\n",
    "#pvalues\n",
    "\n",
    "results = sm.OLS(y, x).fit()\n",
    "pValues = results.pvalues\n",
    "\n",
    "# pValues = list(pValues[pValues<0.05].index)\n",
    "# x = x[pValues]\n",
    "r2 = pd.DataFrame(columns= ['r2_train', 'r2_test', 'MSE'])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "Y_train = Y_train.astype('int32')\n",
    "Y_test = Y_test.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # xgboost\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "# get_features(xgb_model, X_train, Y_train)\n",
    "\n",
    "cols = ['ExterQual_TA', 'OverallQual', 'GarageFinish_Unf', 'KitchenQual_TA', 'LotShape_IR1',\n",
    "         'GrLivArea', 'KitchenQual_Gd', 'TotalBsmtSF', 'GarageType_Detchd', 'BsmtFinSF1']\n",
    "\n",
    "grid_para_tree = [{\n",
    "    \"booster\": [\"gbtree\", \"gblinear\"],\n",
    "    'learning_rate': np.linspace(0.1, 1, 10),\n",
    "    'gamma': range(0, 5),\n",
    "    'min_child_weight':range(1, 6),\n",
    "    \"n_estimators\": np.linspace(100, 200, 5),\n",
    "    \"random_state\": [42]\n",
    "}]\n",
    "# trainX = X_train[cols].astype('int32')\n",
    "# testX = X_test[cols].astype('int32')\n",
    "\n",
    "grid_search_tree = GridSearchCV(xgb_model, grid_para_tree, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search_tree.fit(X_train[cols], Y_train)\n",
    "\n",
    "print(grid_search_tree.best_params_)\n",
    "print(grid_search_tree.best_score_)\n",
    "print(grid_search_tree.score(X_train[cols], Y_train))\n",
    "print(grid_search_tree.score(X_test[cols], Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
